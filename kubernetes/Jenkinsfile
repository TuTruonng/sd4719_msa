pipeline {
  agent any

  // static environment values (change region/cluster name as needed or pass as parameters)
  environment {
    AWS_REGION        = 'ap-southeast-1'
    CLUSTER_NAME      = 'sd4719-eks-cluster'    // override via Jenkins job param or pipeline var
    K8S_APP_DIR       = 'kubernetes'
    K8S_MANIFEST_DIR  = "${K8S_APP_DIR}/aws-manifest-files"           // where your manifests live in the repo
    K8S_NAMESPACE     = 'default'
    NODE_MAX_HEAP     = 256                   // max heap for node builds
    TEMP_MANIFEST_DIR = "temp-aws-manifest-files"
  }

  options {
    skipDefaultCheckout false
    timestamps()
    buildDiscarder(logRotator(numToKeepStr: '30')) // keep last 30 builds
  }

  parameters {
    string(name: 'IMAGE_TAG', defaultValue: '', description: 'Optional image tag. If empty, GIT_COMMIT or BUILD_NUMBER will be used.')
  }

  stages {
    stage('Checkout') {
      steps {
        checkout scm
        script {
          // resolve a stable image tag: prefer param -> git short SHA -> build number
          env.GIT_COMMIT_SHORT = sh(script: "git rev-parse --short HEAD", returnStdout: true).trim()
          if (params.IMAGE_TAG?.trim()) {
            env.IMAGE_TAG = params.IMAGE_TAG
          } else if (env.GIT_COMMIT_SHORT) {
            env.IMAGE_TAG = env.GIT_COMMIT_SHORT
          } else {
            env.IMAGE_TAG = env.BUILD_NUMBER
          }
          echo "Using IMAGE_TAG=${env.IMAGE_TAG}"
        }
      }
    }

    stage('Prepare AWS / ECR Info') {
      steps {
        // Bind AWS creds only for the steps that need them
        withCredentials([[
          $class: 'AmazonWebServicesCredentialsBinding',
          credentialsId: 'aws-creds'
        ]]) {
          sh """
            export AWS_REGION=${AWS_REGION}
            export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
            export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}

            ACCOUNT_ID=\$(aws sts get-caller-identity --query Account --output text --region ${AWS_REGION})
            echo "AWS account: \${ACCOUNT_ID}"
            echo "##teamcity[setParameter name='env.ACCOUNT_ID' value='\${ACCOUNT_ID}']" || true
            echo "ACCOUNT_ID=\${ACCOUNT_ID}" > account.env
          """
        }
        // load ACCOUNT_ID into env for subsequent stages
        script {
          def acct = readFile('account.env').trim().split('=')[-1]
          env.ACCOUNT_ID = acct
          env.ECR_REG = "${env.ACCOUNT_ID}.dkr.ecr.${env.AWS_REGION}.amazonaws.com"
          env.FRONT_IMAGE = "${env.ECR_REG}/frontend:${env.IMAGE_TAG}"
          env.BACK_IMAGE  = "${env.ECR_REG}/backend:${env.IMAGE_TAG}"
          echo "FRONT_IMAGE=${env.FRONT_IMAGE}"
          echo "BACK_IMAGE=${env.BACK_IMAGE}"
        }
      }
    }

    stage('ECR Login') {
      steps {
        withCredentials([[
          $class: 'AmazonWebServicesCredentialsBinding',
          credentialsId: 'aws-creds'
        ]]) {
          sh '''
            set -euo pipefail
            export AWS_REGION=${AWS_REGION}
            export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
            export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
            aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin ${ECR_REG}
            echo "Logged into ECR ${ECR_REG}"
          '''
        }
      }
    }

    // stage('Build & Push Images') {
    //   parallel {
        stage('Build & Push Frontend') {
          steps {
            dir("${K8S_APP_DIR}/src/frontend") {
              withCredentials([[
                $class: 'AmazonWebServicesCredentialsBinding',
                credentialsId: 'aws-creds'
              ]]) {
                sh '''
                  set -euo pipefail
                  export NODE_OPTIONS="--max-old-space-size=$NODE_MAX_HEAP"
                  export DOCKER_BUILDKIT=0

                  echo "Checking if FRONTEND image already exists in ECR..."

                  if aws ecr describe-images \
                      --repository-name frontend \
                        --region $AWS_REGION \
                        --query 'imageDetails | length(@)'
                        --output text 2>/dev/null | grep -q '^[1-9]'; then

                    echo "Frontend image exists => SKIP build & push"

                  else
                    echo "No images found in frontend repository => BUILD + PUSH"

                    echo "Cleaning old Docker images..."
                    docker image prune -f
                    docker images | grep "<none>" || true | awk '{print $3}' | xargs -r docker rmi -f

                    docker build -t $FRONT_IMAGE .
                    docker push $FRONT_IMAGE
                  fi
                '''
              }
            }
          }
        }
        stage('Build & Push Backend') {
          steps {
            dir("${K8S_APP_DIR}/src/backend") {
              withCredentials([[
                $class: 'AmazonWebServicesCredentialsBinding',
                credentialsId: 'aws-creds'
              ]]) {
                sh '''
                  set -euo pipefail
                  export NODE_OPTIONS="--max-old-space-size=$NODE_MAX_HEAP"
                  export DOCKER_BUILDKIT=0

                  echo "Checking if BACKEND image already exists in ECR..."

                  if aws ecr describe-images \
                      --repository-name backend \
                      --region $AWS_REGION \
                      --query 'imageDetails | length(@)'
                      --output text 2>/dev/null | grep -q '^[1-9]'; then

                    echo "Backend image exists => SKIP build & push"

                  else
                    echo "No images found in backend repository => BUILD + PUSH"

                    echo "Cleaning old Docker images..."
                    docker image prune -f
                    docker images | grep "<none>" || true | awk '{print $3}' | xargs -r docker rmi -f

                    docker build -t $BACK_IMAGE .
                    docker push $BACK_IMAGE
                  fi
                '''
              }
            }
          }
        }
    //    }
    // }

    stage('Prepare K8s Manifests') {
      steps {
        // Prefer kubectl rollout or ``kubectl set image`` instead of editing files then apply
        // We'll create a temporary copy of manifests and replace images there, then archive
        sh """
          set -euo pipefail
          mkdir -p ${TEMP_MANIFEST_DIR}

          echo "Copying manifests from: ${K8S_MANIFEST_DIR}"
          cp ${K8S_MANIFEST_DIR}/*.yaml ${TEMP_MANIFEST_DIR}/ || true

          echo "Patching manifest imagesâ€¦"

          # Update frontend image
          sed -i "s|image:.*frontend.*|image: ${env.FRONT_IMAGE}|g" ${TEMP_MANIFEST_DIR}/frontend.yaml || true

          # Update backend image
          sed -i "s|image:.*backend.*|image: ${env.BACK_IMAGE}|g"  ${TEMP_MANIFEST_DIR}/backend.yaml || true

          # keep the originals for traceability and archive the updated ones
          ls -la ${TEMP_MANIFEST_DIR}
        """
        archiveArtifacts artifacts: "${TEMP_MANIFEST_DIR}/*.yaml", fingerprint: true
      }
    }

    stage('Deploy to EKS') {
      steps {
        withCredentials([[
          $class: 'AmazonWebServicesCredentialsBinding',
          credentialsId: 'aws-creds'
        ]]) {
          sh """
            set -euo pipefail
            export AWS_REGION=${AWS_REGION}
            export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
            export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}

            # update kubeconfig for CLUSTER_NAME (must exist and IAM creds must be allowed)
            aws eks update-kubeconfig --region ${AWS_REGION} --name ${CLUSTER_NAME}

            # Option A: use kubectl apply on manifests (works for first deploy)
            kubectl apply --validate=false -f ${TEMP_MANIFEST_DIR}/mongodb.yaml || true
            kubectl apply --validate=false -f ${TEMP_MANIFEST_DIR}/backend.yaml
            kubectl apply --validate=false -f ${TEMP_MANIFEST_DIR}/frontend.yaml

            # Option B (preferred for live update): update deployments image
            # kubectl -n default set image deployment/backend backend=${BACK_IMAGE} --record || true
            # kubectl -n default set image deployment/frontend frontend=${FRONT_IMAGE} --record || true

            # wait for rollout to complete
            kubectl rollout status deployment/backend --timeout=120s || true
            kubectl rollout status deployment/frontend --timeout=120s || true
          """
        }
      }
    }

    stage('Verify') {
      steps {
        sh '''
          echo "Pods (default):"
          kubectl get pods -n ${K8S_NAMESPACE} -o wide || true
          echo "Services:"
          kubectl get svc -n default || true
        '''
      }
    }
  } // stages

  post {
    success {
      echo "Deployment succeeded: frontend -> ${env.FRONT_IMAGE}, backend -> ${env.BACK_IMAGE}"
    }
    failure {
      sh 'kubectl get pods --all-namespaces || true'
      echo "Deployment failed. Check console output and logs."
    }
    cleanup {
      // Optional cleanup: remove local images to save disk
      sh 'docker image prune -af || true'
    }
  }
}
